{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ecbf338-f7f1-4b9a-bb12-9e6eafa52a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyshark\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56793f86-ff81-4b59-8ee7-694903b41704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted all files from augmented_data.zip → augmented_data/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"augmented_data.zip\"\n",
    "out_dir  = \"augmented_data\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(out_dir)\n",
    "\n",
    "print(f\"Extracted all files from {zip_path} → {out_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "852afe12-55e0-48f5-8bdf-885da6710b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyshark in /opt/conda/lib/python3.10/site-packages (0.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from pyshark) (5.4.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from pyshark) (3.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pyshark) (23.1)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from pyshark) (1.4.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a95fd51e-0220-4f08-a34c-5d0ef9c2e0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scapy in /opt/conda/lib/python3.10/site-packages (2.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40c6b082-510b-496e-858a-a2c6f0be4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2025-6-10 Python-3.10.13 torch-2.2.1 CUDA:0 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# 01-imports.py ───────────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json, math, itertools, time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from scapy.all import rdpcap   # needs sudo on some platforms\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)  # first run downloads weights\n",
    "yolo.conf = 0.25  # confidence threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "080b97f8-166b-412e-a3fd-8dd2924fb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02-pcap-features.py ─────────────────────────────────────────────────────────\n",
    "def extract_pcap_features(pcap_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Lightweight flow-level summary of a PCAP.\n",
    "    Returns a feature dict (flat, numeric) that can go straight into a DataFrame.\n",
    "    \"\"\"\n",
    "    packets = rdpcap(str(pcap_path))\n",
    "    if not packets:\n",
    "        return {\"fname\": pcap_path.name, \"tot_pkts\": 0, \"tot_bytes\": 0}\n",
    "\n",
    "    t0, t1 = packets[0].time, packets[-1].time\n",
    "    duration = max(t1 - t0, 1e-6)\n",
    "\n",
    "    sizes = [len(pkt) for pkt in packets]\n",
    "    protocols = Counter(pkt.name for pkt in packets)\n",
    "    l4 = Counter(pkt.lastlayer().name for pkt in packets)\n",
    "\n",
    "    ips = [(pkt[0][1].src, pkt[0][1].dst)   # naive; works for IPv4 in most traces\n",
    "           for pkt in packets if pkt.haslayer('IP')]\n",
    "\n",
    "    src_ips = Counter(src for src, _ in ips)\n",
    "    dst_ips = Counter(dst for _, dst in ips)\n",
    "\n",
    "    feats = {\n",
    "        \"fname\"        : pcap_path.name,\n",
    "        \"tot_pkts\"     : len(packets),\n",
    "        \"tot_bytes\"    : sum(sizes),\n",
    "        \"mean_pkt_len\" : float(np.mean(sizes)),\n",
    "        \"std_pkt_len\"  : float(np.std(sizes)),\n",
    "        \"duration\"     : duration,\n",
    "        \"pkts_per_sec\" : len(packets)/duration,\n",
    "        \"bytes_per_sec\": sum(sizes)/duration,\n",
    "        \"uniq_src_ip\"  : len(src_ips),\n",
    "        \"uniq_dst_ip\"  : len(dst_ips),\n",
    "        # Top-3 protocol ratios\n",
    "        **{f\"proto_{p}\": protocols[p]/len(packets) for p in (\"TCP\", \"UDP\", \"ICMP\")},\n",
    "        **{f\"l4_{l}\": l4[l]/len(packets) for l in (\"Raw\", \"HTTP\")},  # extend as you wish\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4cfb664e-c6c4-422c-8612-9b2fc85356e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03-video-features.py ────────────────────────────────────────────────────────\n",
    "def _calc_entropy(hist):\n",
    "    p = hist / (hist.sum() + 1e-12)\n",
    "    return -(p * np.log2(p + 1e-12)).sum()\n",
    "\n",
    "def extract_video_features(video_path: Path,\n",
    "                           frame_skip: int = 15,\n",
    "                           max_frames: int = 600) -> dict:\n",
    "    \"\"\"\n",
    "    * Motion magnitude (simple frame-diff)\n",
    "    * Color histogram entropy\n",
    "    * YOLO object counts (knife, gun, person, etc.)  — default model ≈ COCO\n",
    "    Returns a dict of numeric features.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps   = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Stats we accumulate\n",
    "    motion_vals, entropy_vals = [], []\n",
    "    yolo_counts = Counter()\n",
    "\n",
    "    last_gray = None\n",
    "    processed = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(frame_count):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            if i % frame_skip: continue\n",
    "            processed += 1\n",
    "            if processed > max_frames: break\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if last_gray is not None:\n",
    "                diff = cv2.absdiff(gray, last_gray)\n",
    "                motion_vals.append(diff.mean())\n",
    "            last_gray = gray\n",
    "\n",
    "            # histogram entropy\n",
    "            hist = cv2.calcHist([frame],[0],None,[256],[0,256]).flatten()\n",
    "            entropy_vals.append(_calc_entropy(hist))\n",
    "\n",
    "            # object detection\n",
    "            results = yolo(frame, size=640)\n",
    "            for cls in results.pred[0][:,5].tolist():  # integer class ids\n",
    "                yolo_counts[int(cls)] += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Map YOLO class ids to human labels (subset)\n",
    "    coco_names = yolo.names\n",
    "    weapon_labels = {\"knife\", \"sports ball\", \"baseball bat\", \"baseball glove\"}\n",
    "    person_labels = {\"person\"}\n",
    "\n",
    "    counts = Counter({coco_names[k]: v for k, v in yolo_counts.items()\n",
    "                      if coco_names[k] in weapon_labels | person_labels})\n",
    "\n",
    "    feats = {\n",
    "        \"fname\"           : video_path.name,\n",
    "        \"fps\"             : fps,\n",
    "        \"frames_proc\"     : processed,\n",
    "        \"mean_motion\"     : float(np.mean(motion_vals)) if motion_vals else 0.0,\n",
    "        \"std_motion\"      : float(np.std(motion_vals))  if motion_vals else 0.0,\n",
    "        \"mean_entropy\"    : float(np.mean(entropy_vals)) if entropy_vals else 0.0,\n",
    "        \"std_entropy\"     : float(np.std(entropy_vals))  if entropy_vals else 0.0,\n",
    "        # object counts (use .get to default to 0)\n",
    "        \"persons\"         : counts.get(\"person\", 0),\n",
    "        \"knives\"          : counts.get(\"knife\", 0),\n",
    "        \"bats\"            : counts.get(\"baseball bat\", 0),\n",
    "        \"balls\"           : counts.get(\"sports ball\", 0),\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60b47306-44e2-4547-be46-c9f985cb37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04-batch-runner.py  (revised) ──────────────────────────────────────────────\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
    "PCAP_EXTS  = {\".pcap\", \".pcapng\"}\n",
    "\n",
    "def list_files(root: Path, exts) -> list[Path]:\n",
    "    \"\"\"Recursively list files whose suffix (lower-case) is in `exts`.\"\"\"\n",
    "    return sorted(p for p in root.rglob(\"*\") if p.suffix.lower() in exts)\n",
    "\n",
    "def build_feature_table(pcap_dir: Path, video_dir: Path) -> pd.DataFrame:\n",
    "    # ---------- PCAP ----------\n",
    "    pcap_paths = list_files(pcap_dir, PCAP_EXTS)\n",
    "    if not pcap_paths:\n",
    "        print(f\"[WARN] No PCAPs found under {pcap_dir.resolve()}\")\n",
    "    pcap_feats = [extract_pcap_features(p) for p in tqdm(pcap_paths, desc=\"PCAP\")]\n",
    "    df_pcap = (\n",
    "        pd.DataFrame(pcap_feats).set_index(\"fname\").add_prefix(\"pcap_\")\n",
    "        if pcap_feats else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "    # ---------- VIDEO ----------\n",
    "    vid_paths = list_files(video_dir, VIDEO_EXTS)\n",
    "    if not vid_paths:\n",
    "        print(f\"[WARN] No videos found under {video_dir.resolve()}\")\n",
    "    video_feats = [extract_video_features(v) for v in tqdm(vid_paths, desc=\"VIDEO\")]\n",
    "    df_video = (\n",
    "        pd.DataFrame(video_feats).set_index(\"fname\").add_prefix(\"vid_\")\n",
    "        if video_feats else pd.DataFrame()\n",
    "    )\n",
    "\n",
    "    # ---------- MERGE ----------\n",
    "    dfs = [df for df in (df_pcap, df_video) if not df.empty]\n",
    "    if not dfs:\n",
    "        raise RuntimeError(\"No files processed – double-check your folder paths & extensions.\")\n",
    "    return (\n",
    "        pd.concat(dfs, axis=0, sort=False)\n",
    "          .reset_index()\n",
    "          .rename(columns={\"index\": \"file\"})\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9de6c2ef-ff8e-4019-8302-e4ced40985b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCAP good files : 120\n",
      "Video candidates: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6696c4c37a4dbf9d5678a944200be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PCAP:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db1e741cccc4dfb9d7c9e61f3f44169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VIDEO:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 05-run-feature-extraction.py ───────────────────────────────────────────────\n",
    "# <<< EDIT THESE >>>  (absolute or relative paths)\n",
    "# --------------------------------------------------------------------------\n",
    "# 00-constants.py (add after your imports)\n",
    "JUNK_PREFIXES = {\"._\"}                      # macOS resource forks\n",
    "VIDEO_EXTS    = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
    "PCAP_EXTS     = {\".pcap\", \".pcapng\", \".pcap.gz\", \".pcapng.gz\"}\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# util: list_files()  – add a junk-file filter\n",
    "def list_files(root: Path, exts) -> list[Path]:\n",
    "    return sorted(\n",
    "        p for p in root.rglob(\"*\")\n",
    "        if p.suffix.lower() in exts and not p.name.startswith(tuple(JUNK_PREFIXES))\n",
    "    )\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# util: _pyshark_summary() – auto-adapt to PyShark version\n",
    "import inspect\n",
    "def _pyshark_summary(path: Path, max_pkts: int = 100_000) -> dict:\n",
    "    kwargs = dict(keep_packets=False, override_prefs={\"transport_layer\": \"true\"})\n",
    "    if \"decode_tunnels\" in inspect.signature(pyshark.FileCapture).parameters:\n",
    "        kwargs[\"decode_tunnels\"] = True\n",
    "\n",
    "    cap = pyshark.FileCapture(str(path), **kwargs)\n",
    "\n",
    "    bytes_total = pkts = 0\n",
    "    protocols   = Counter(); src_ips = Counter(); dst_ips = Counter()\n",
    "    try:\n",
    "        for pkt in cap:\n",
    "            pkts += 1\n",
    "            bytes_total += int(getattr(pkt.frame_info, \"len\", 0))\n",
    "            protos = getattr(pkt.frame_info, \"protocols\", \"\")\n",
    "            protocols[protos.split(\":\")[-1]] += 1\n",
    "            if hasattr(pkt, \"ip\"):\n",
    "                src_ips[pkt.ip.src] += 1\n",
    "                dst_ips[pkt.ip.dst] += 1\n",
    "            if pkts >= max_pkts:\n",
    "                break\n",
    "    finally:\n",
    "        cap.close()        # ensures _running_processes exists before __del__\n",
    "    return dict(tot_pkts=pkts,\n",
    "                tot_bytes=bytes_total,\n",
    "                uniq_src_ip=len(src_ips),\n",
    "                uniq_dst_ip=len(dst_ips),\n",
    "                **{f\"proto_{p}\": protocols[p]/pkts for p in (\"tcp\", \"udp\", \"icmp\") if pkts})\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def extract_pcap_features(pcap_path: Path) -> dict:\n",
    "    \"\"\"Robust extractor with gzip+pcapng support and PyShark fallback.\"\"\"\n",
    "    header = _sniff_magic(pcap_path)\n",
    "    try:\n",
    "        raw = _open_maybe_gzip(pcap_path)\n",
    "        # ---------- Try Scapy ----------\n",
    "        if raw[:4] in MAGIC_PCAP | MAGIC_PCAPNG:\n",
    "            packets = rdpcap(io.BytesIO(raw))   # we can feed bytes-like object\n",
    "        else:\n",
    "            raise Scapy_Exception(\"Unrecognised magic\")\n",
    "        if not packets:                       # empty file?\n",
    "            raise Scapy_Exception(\"0 packets\")\n",
    "        t0, t1 = packets[0].time, packets[-1].time\n",
    "        duration = max(t1 - t0, 1e-6)\n",
    "        sizes = [len(pkt) for pkt in packets]\n",
    "        protocols = Counter(pkt.name for pkt in packets)\n",
    "        l4 = Counter(pkt.lastlayer().name for pkt in packets)\n",
    "        ips  = [(pkt[0][1].src, pkt[0][1].dst) for pkt in packets if pkt.haslayer('IP')]\n",
    "        src_ips, dst_ips = Counter(src for src, _ in ips), Counter(dst for _, dst in ips)\n",
    "        feats_core = dict(\n",
    "            tot_pkts=len(packets),\n",
    "            tot_bytes=sum(sizes),\n",
    "            mean_pkt_len=float(np.mean(sizes)),\n",
    "            std_pkt_len=float(np.std(sizes)),\n",
    "            duration=duration,\n",
    "            pkts_per_sec=len(packets)/duration,\n",
    "            bytes_per_sec=sum(sizes)/duration,\n",
    "            uniq_src_ip=len(src_ips),\n",
    "            uniq_dst_ip=len(dst_ips),\n",
    "        )\n",
    "        feats_proto = {f\"proto_{p}\": protocols[p]/len(packets) for p in (\"TCP\",\"UDP\",\"ICMP\")}\n",
    "        feats_l4    = {f\"l4_{l}\": l4[l]/len(packets) for l in (\"Raw\",\"HTTP\")}\n",
    "        feats = {**feats_core, **feats_proto, **feats_l4}\n",
    "\n",
    "    except Exception as scapy_err:\n",
    "        # ---------- PyShark fallback ----------\n",
    "        try:\n",
    "            feats = _pyshark_summary(pcap_path)\n",
    "            feats.setdefault(\"mean_pkt_len\", 0)\n",
    "            feats.setdefault(\"std_pkt_len\", 0)\n",
    "            feats.setdefault(\"duration\",     0)\n",
    "            feats.setdefault(\"pkts_per_sec\", 0)\n",
    "            feats.setdefault(\"bytes_per_sec\",0)\n",
    "        except Exception as py_err:\n",
    "            print(f\"[ERROR] {pcap_path.name}: {scapy_err} ; fallback failed ({py_err})\")\n",
    "            return {\"fname\": pcap_path.name, \"tot_pkts\": 0, \"tot_bytes\": 0, \"error\": 1}\n",
    "\n",
    "    feats[\"fname\"] = pcap_path.name\n",
    "    feats.setdefault(\"error\", 0)\n",
    "    return feats\n",
    "\n",
    "# quick sanity\n",
    "\n",
    "\n",
    "PCAP_FOLDER  = Path(\"augmented_data/augmented_data/pcap\")        # e.g. Path(\"/home/me/captures\")\n",
    "VIDEO_FOLDER = Path(\"augmented_data/augmented_data/video\")        # e.g. Path(\"/home/me/cctv\")\n",
    "print(\"PCAP good files :\", len(list_files(PCAP_FOLDER, PCAP_EXTS)))\n",
    "print(\"Video candidates:\", len(list_files(VIDEO_FOLDER, VIDEO_EXTS)))\n",
    "\n",
    "df = build_feature_table(PCAP_FOLDER, VIDEO_FOLDER)\n",
    "# print(\"Final df shape:\", df.shape)\n",
    "# df[df[\"pcap_error\"] == 1].head()        # ⇠ optional: see which pcaps failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69385752-cb52-4542-b991-17e4d82b0d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ACTUAL SHAPE: (201, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>pcap_tot_pkts</th>\n",
       "      <th>pcap_tot_bytes</th>\n",
       "      <th>pcap_mean_pkt_len</th>\n",
       "      <th>pcap_std_pkt_len</th>\n",
       "      <th>...</th>\n",
       "      <th>vid_std_entropy</th>\n",
       "      <th>vid_persons</th>\n",
       "      <th>vid_knives</th>\n",
       "      <th>vid_bats</th>\n",
       "      <th>vid_balls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291c-delays.pcap</td>\n",
       "      <td>587.0</td>\n",
       "      <td>472874.0</td>\n",
       "      <td>805.577513</td>\n",
       "      <td>457.673320</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291c-drops.pcap</td>\n",
       "      <td>568.0</td>\n",
       "      <td>455519.0</td>\n",
       "      <td>801.970070</td>\n",
       "      <td>458.500930</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291c-speed1.1.pcap</td>\n",
       "      <td>587.0</td>\n",
       "      <td>472874.0</td>\n",
       "      <td>805.577513</td>\n",
       "      <td>457.673320</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-speed1.1.pcap</td>\n",
       "      <td>281.0</td>\n",
       "      <td>238761.0</td>\n",
       "      <td>849.683274</td>\n",
       "      <td>441.244587</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-speed2.pcap</td>\n",
       "      <td>281.0</td>\n",
       "      <td>238761.0</td>\n",
       "      <td>849.683274</td>\n",
       "      <td>441.244587</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                fname  pcap_tot_pkts  pcap_tot_bytes  pcap_mean_pkt_len  \\\n",
       "0    291c-delays.pcap          587.0        472874.0         805.577513   \n",
       "1     291c-drops.pcap          568.0        455519.0         801.970070   \n",
       "2  291c-speed1.1.pcap          587.0        472874.0         805.577513   \n",
       "3     A-speed1.1.pcap          281.0        238761.0         849.683274   \n",
       "4       A-speed2.pcap          281.0        238761.0         849.683274   \n",
       "\n",
       "   pcap_std_pkt_len  ... vid_std_entropy vid_persons vid_knives  vid_bats  \\\n",
       "0        457.673320  ...             NaN         NaN        NaN       NaN   \n",
       "1        458.500930  ...             NaN         NaN        NaN       NaN   \n",
       "2        457.673320  ...             NaN         NaN        NaN       NaN   \n",
       "3        441.244587  ...             NaN         NaN        NaN       NaN   \n",
       "4        441.244587  ...             NaN         NaN        NaN       NaN   \n",
       "\n",
       "   vid_balls  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\">>> ACTUAL SHAPE:\", df.shape)      # should print (80, 26)\n",
    "\n",
    "df.head()                                 # 5 example rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fab15b25-a90d-4926-9a3d-87a67f3d34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_features(video_path: Path,\n",
    "                           target_frames: int = 60,\n",
    "                           max_frames: int = 2000,\n",
    "                           yolo_model=yolo,               # can inject custom model\n",
    "                           yolo_conf: float | None = None):\n",
    "    \"\"\"\n",
    "    Sample enough frames to hit `target_frames`, but stop at `max_frames`.\n",
    "    Returns a flat feature dict (all numeric except 'fname').\n",
    "    \"\"\"\n",
    "    if yolo_conf is not None:\n",
    "        yolo_model.conf = yolo_conf\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return {\"fname\": video_path.name, \"vid_error\": 1}\n",
    "\n",
    "    fps   = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1\n",
    "    skip  = max(total // target_frames, 1)               # adaptive sampling stride\n",
    "\n",
    "    motion_vals, entropy_vals = [], []\n",
    "    counts = Counter(); last_gray = None\n",
    "    processed = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(total):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if idx % skip:\n",
    "                continue\n",
    "            processed += 1\n",
    "            if processed > max_frames:\n",
    "                break\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if last_gray is not None:\n",
    "                motion_vals.append(cv2.absdiff(gray, last_gray).mean())\n",
    "            last_gray = gray\n",
    "\n",
    "            hist = cv2.calcHist([frame],[0],None,[256],[0,256]).flatten()\n",
    "            entropy_vals.append(_calc_entropy(hist))\n",
    "\n",
    "            res = yolo_model(frame, size=640)\n",
    "            for cls in res.pred[0][:, 5].tolist():\n",
    "                counts[int(cls)] += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    coco = yolo_model.names\n",
    "    feats = {\n",
    "        \"fname\"           : video_path.name,\n",
    "        \"vid_fps\"         : fps,\n",
    "        \"vid_frames_total\": total,\n",
    "        \"vid_frames_proc\" : processed,\n",
    "        \"vid_mean_motion\" : float(np.mean(motion_vals)) if motion_vals else 0,\n",
    "        \"vid_std_motion\"  : float(np.std(motion_vals))  if motion_vals else 0,\n",
    "        \"vid_mean_entropy\": float(np.mean(entropy_vals)) if entropy_vals else 0,\n",
    "        \"vid_std_entropy\" : float(np.std(entropy_vals))  if entropy_vals else 0,\n",
    "        \"vid_persons\"     : counts.get(next((k for k,v in coco.items() if v==\"person\"), -1), 0),\n",
    "        \"vid_knives\"      : counts.get(next((k for k,v in coco.items() if v==\"knife\"),  -1), 0),\n",
    "        \"vid_bats\"        : counts.get(next((k for k,v in coco.items() if v==\"baseball bat\"), -1), 0),\n",
    "        \"vid_balls\"       : counts.get(next((k for k,v in coco.items() if v==\"sports ball\"), -1), 0),\n",
    "        \"vid_error\"       : 0,\n",
    "    }\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa6652ac-d561-45b5-873a-0872ccc0ae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fname', 'pcap_tot_pkts', 'pcap_tot_bytes', 'pcap_mean_pkt_len',\n",
      "       'pcap_std_pkt_len', 'pcap_duration', 'pcap_pkts_per_sec',\n",
      "       'pcap_bytes_per_sec', 'pcap_uniq_src_ip', 'pcap_uniq_dst_ip',\n",
      "       'pcap_proto_TCP', 'pcap_proto_UDP', 'pcap_proto_ICMP', 'pcap_l4_Raw',\n",
      "       'pcap_l4_HTTP', 'pcap_error', 'vid_fps', 'vid_frames_proc',\n",
      "       'vid_mean_motion', 'vid_std_motion', 'vid_mean_entropy',\n",
      "       'vid_std_entropy', 'vid_persons', 'vid_knives', 'vid_bats', 'vid_balls',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31ba98e9-75fe-483d-9205-7a5a0568faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     vid_frames_proc  vid_persons  vid_mean_motion\n",
      "120              6.0          5.0        12.119514\n",
      "121              6.0          5.0        11.025236\n",
      "122              3.0          3.0         8.958849\n",
      "123              2.0          2.0        13.239454\n",
      "124              4.0          4.0         7.380272\n"
     ]
    }
   ],
   "source": [
    "video_df = df[df['vid_frames_proc'].notnull()]\n",
    "print(video_df[['vid_frames_proc', 'vid_persons', 'vid_mean_motion']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e7705044-d625-463c-8e47-4479e714af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature matrix shape: (201, 25)\n",
      "✅ Label vector shape   : (201,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define label column and validate ----------------------------\n",
    "LABEL_COL = \"label\"\n",
    "assert LABEL_COL in df.columns, f\"❌ '{LABEL_COL}' column missing\"\n",
    "\n",
    "# --- 2. Identify non-feature/meta columns ---------------------------\n",
    "# Only drop columns that exist\n",
    "maybe_non_features = [\"fname\", \"file_type\", LABEL_COL]\n",
    "NON_FEATURES = [col for col in maybe_non_features if col in df.columns]\n",
    "\n",
    "# --- 3. Create feature matrix and label vector ----------------------\n",
    "X = df.drop(columns=NON_FEATURES).astype(np.float32)\n",
    "y = df[LABEL_COL].astype(int)\n",
    "\n",
    "# Optional: fill missing values (e.g., video features missing for .pcap files)\n",
    "X = X.fillna(0.0)\n",
    "\n",
    "# --- 4. Inspect shape -----------------------------------------------\n",
    "print(\"✅ Feature matrix shape:\", X.shape)\n",
    "print(\"✅ Label vector shape   :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9205d284-ea7a-4129-a6b5-7afac3b4f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pcap_only = df[df['vid_frames_proc'].isnull()]\n",
    "video_only = df[df['vid_frames_proc'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "415d3adf-7415-403d-8a89-a6825c7e4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.9803921568627451\n",
      "\n",
      "📊 Confusion Matrix:\n",
      "[[48  0]\n",
      " [ 1  2]]\n",
      "\n",
      "📝 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        48\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98        51\n",
      "   macro avg       0.99      0.83      0.89        51\n",
      "weighted avg       0.98      0.98      0.98        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n📊 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n📝 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c95aaaee-470e-429c-9519-b116d6d01f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.bar(range(10), importances[indices[:10]])\n",
    "plt.xticks(range(10), feature_names[indices[:10]], rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2fcbe1ad-e399-49e9-832a-9bab9afc7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-15 influential features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vid_mean_entropy      0.114471\n",
       "pcap_mean_pkt_len     0.100396\n",
       "pcap_tot_pkts         0.089721\n",
       "pcap_tot_bytes        0.074945\n",
       "vid_frames_proc       0.071043\n",
       "pcap_duration         0.065078\n",
       "vid_std_entropy       0.059878\n",
       "vid_mean_motion       0.055707\n",
       "vid_std_motion        0.054616\n",
       "vid_persons           0.054607\n",
       "pcap_bytes_per_sec    0.054310\n",
       "pcap_l4_Raw           0.053589\n",
       "pcap_std_pkt_len      0.050567\n",
       "pcap_pkts_per_sec     0.049447\n",
       "pcap_uniq_dst_ip      0.022556\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 08-feature-importance.py ───────────────────────────────────────────────────\n",
    "importances = pd.Series(clf.feature_importances_, index=X.columns)\\\n",
    "               .sort_values(ascending=False)\n",
    "\n",
    "print(\"Top-15 influential features:\")\n",
    "display(importances.head(15))\n",
    "\n",
    "# Optional: visual bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "importances.head(25).plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature importance – RandomForest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b46498f3-e3d8-4e8a-9574-d497bca005a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "0    191\n",
      "1     10\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution:\")\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "444e84ff-c6cf-4f54-abc6-7183c2ce8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m745.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e9fe71b-23bc-409a-923d-9829a0036456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.27.3 xgboost-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75aadaad-0df9-464e-9656-da653da64c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC per fold: [      0.091       0.125        0.05       0.083]  mean = 0.087\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ratio = (y == 0).sum() / (y == 1).sum()          # 76 / 4 = 19\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight = ratio,                     # **key line**\n",
    "    eval_metric = \"aucpr\",\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "auc = cross_val_score(xgb, X, y, cv=skf, scoring=\"average_precision\")\n",
    "print(\"PR-AUC per fold:\", auc.round(3), \" mean =\", auc.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec22fa57-258c-4871-81aa-686116431e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (80) does not match length of index (201)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m iso \u001b[38;5;241m=\u001b[39m IsolationForest(contamination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m iso\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39miso\u001b[38;5;241m.\u001b[39mscore_samples(X)          \u001b[38;5;66;03m# higher = more suspicious\u001b[39;00m\n\u001b[1;32m      6\u001b[0m top \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      7\u001b[0m display(top[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (80) does not match length of index (201)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso.fit(X)\n",
    "\n",
    "df[\"anomaly\"] = -iso.score_samples(X)          # higher = more suspicious\n",
    "top = df.sort_values(\"anomaly\", ascending=False).head(10)\n",
    "display(top[[\"fname\", \"anomaly\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e75ef6-9ac8-471c-a4db-ba60ffcd940a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
